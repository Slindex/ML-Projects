{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Management libraries\n",
    "import tarfile\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "# Data Analytics libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML libraries\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function downloads the Housing data zip file from a GitHub repository, create the 'data' directory if not exists and finally extracts the content from the zip file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadHousingData():\n",
    "\n",
    "    # Defining the zip path and the csv path\n",
    "    zipfilePath = Path('data/housing.tgz')\n",
    "    housingPath = Path('data/housing.csv')\n",
    "\n",
    "    # Checking if the zip file not exists\n",
    "    if not zipfilePath.is_file():\n",
    "\n",
    "        # Making the data/ directory\n",
    "        Path('data').mkdir(parents=True, exist_ok=True)\n",
    "        print('data/ directory created')\n",
    "\n",
    "        # Setting the URL for downloading the data\n",
    "        URL = 'https://github.com/ageron/data/raw/main/housing.tgz'\n",
    "\n",
    "        # Downloading the data from the URL into the zip path\n",
    "        urllib.request.urlretrieve(URL, zipfilePath)\n",
    "        print(f'data downloaded from {URL}')\n",
    "\n",
    "    # Checking if the csv file not exists\n",
    "    if not housingPath.is_file():\n",
    "\n",
    "        # Open the zip file and extract the content\n",
    "        with tarfile.open(zipfilePath) as housing_zip:\n",
    "            housing_zip.extractall(path='data')\n",
    "        print('Content Extracted into data/')\n",
    "\n",
    "        # Move the csv file to the data directory\n",
    "        csvPath = Path('data/housing/housing.csv')\n",
    "        csvPath.rename(Path('data/housing.csv'))\n",
    "\n",
    "        # Remove the housing/ directory from data/\n",
    "        housingDirPath = Path('data/housing')\n",
    "        housingDirPath.rmdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function downloads a graph generated by matplotlib with the specified name, graph extension and resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveGraph(graph_id:str, tight_layout=True, graph_extension='png', resolution=300):\n",
    "\n",
    "    # Creating the image directory if not exists\n",
    "    imagesPath = Path('images')\n",
    "    imagesPath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Defining the path for saving the graphs\n",
    "    graphPath = imagesPath/f'{graph_id}.{graph_extension}'\n",
    "\n",
    "    # Checking if the tight_layout is True\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    # Saving the graph with the name, format and dpi resolution\n",
    "    plt.savefig(graphPath, format=graph_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Data Splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function splits a dataframe randomly into a test and train set for ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomDataSplitter(data, test_ratio=0.2):\n",
    "\n",
    "    # Creates the list of indexes and calculates the number of rows for the test set\n",
    "    indexList = np.random.permutation(len(data))\n",
    "    testSize = int(len(data) * test_ratio)\n",
    "\n",
    "    # Creates the test and train list of indexes based on the test size\n",
    "    testIndexes = indexList[:testSize]\n",
    "    trainIndexes = indexList[testSize:]\n",
    "\n",
    "    # Creates the test and train sets based on the original dataframe\n",
    "    testSet = data.iloc[testIndexes]\n",
    "    trainSet = data.iloc[trainIndexes]\n",
    "\n",
    "    return trainSet, testSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
